{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[PIT] P3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qncY3FktdgMI"
      },
      "source": [
        "# PIT - Práctica 3: Diarización de Locutores mediante Redes Neuronales \"End-to-End\"\n",
        "\n",
        "**Alicia Lozano Díez**\n",
        " \n",
        "6 de mayo de 2021\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww3BS9Yoxk-6"
      },
      "source": [
        "## Objetivo\n",
        "\n",
        "El objetivo de esta práctica es implementar un sistema de diarización de locutores \"end-to-end\" basado en redes neuronales recurrentes LSTM.\n",
        "\n",
        "### Materiales\n",
        "\n",
        "- Guión y código (.ipynb) de la práctica - Moodle\n",
        "- Datos y RTTM de entrenamiento (subconjunto de VoxConverse) * - One Drive (https://dauam-my.sharepoint.com/:u:/g/personal/alicia_lozano_uam_es/EVUnDzRYb91Gv8DkmGhLer0B0Uuvuow452szEsc0ikyIUA?download=1)\n",
        "- Artículo: \n",
        "_Yusuke Fujita et al._, \"End-to-End Neural Speaker Diarization with Permutation-Free Objectives\", Interspeech 2019\n",
        "https://www.isca-speech.org/archive/Interspeech_2019/pdfs/2899.pdf\n",
        "\n",
        "**CUIDADO: * Los datos proporcionados son de uso exclusivo para esta práctica. No tiene permiso para copiar, distribuir o utilizar el corpus para ningún otro propósito.** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg36ewdK3w1c"
      },
      "source": [
        "# 1. Preparando el entorno\n",
        "\n",
        "## 1.1. Descarga de los datos de entrenamiento\n",
        "\n",
        "Como en las prácticas anteriores, descargaremos la lista de identificadores de los datos de entrenamiento (fichero **train_DIAR_2spk.lst** de Moodle) y los datos de entrenamiento utilizando el script **data_download_onedrive_DIAR_2spk.sh**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2NmZBo-34xk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e15394a-b21a-40fe-c9bd-ff234e7a92a4"
      },
      "source": [
        "import os \n",
        "\n",
        "download = True\n",
        "DIR = \"/content/drive/My Drive/pit/P3/\"\n",
        "\n",
        "if download and not os.path.isdir(\"data\"):\n",
        "    #from google.colab import drive\n",
        "    #drive.mount(\"/content/drive\", force_remount = True)\n",
        "    %cd \"$DIR\"\n",
        "    !cp *.lst /content/\n",
        "    !cp *.sh /content\n",
        "    %cd /content\n",
        "    !chmod 755 *.sh\n",
        "    !./data_download_onedrive_DIAR_2spk.sh"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/pit/P3\n",
            "/content\n",
            "--2021-05-12 14:13:48--  https://dauam-my.sharepoint.com/:u:/g/personal/alicia_lozano_uam_es/EVUnDzRYb91Gv8DkmGhLer0B0Uuvuow452szEsc0ikyIUA?download=1\n",
            "Resolving dauam-my.sharepoint.com (dauam-my.sharepoint.com)... 13.107.136.9\n",
            "Connecting to dauam-my.sharepoint.com (dauam-my.sharepoint.com)|13.107.136.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /personal/alicia_lozano_uam_es/Documents/PIT/train_2spk.zip?originalPath=aHR0cHM6Ly9kYXVhbS1teS5zaGFyZXBvaW50LmNvbS86dTovZy9wZXJzb25hbC9hbGljaWFfbG96YW5vX3VhbV9lcy9FVlVuRHpSWWI5MUd2OERrbUdoTGVyMEIwVXV2dW93NDUyc3pFc2MwaWt5SVVBP3J0aW1lPU0wU0RLVkFWMlVn [following]\n",
            "--2021-05-12 14:13:48--  https://dauam-my.sharepoint.com/personal/alicia_lozano_uam_es/Documents/PIT/train_2spk.zip?originalPath=aHR0cHM6Ly9kYXVhbS1teS5zaGFyZXBvaW50LmNvbS86dTovZy9wZXJzb25hbC9hbGljaWFfbG96YW5vX3VhbV9lcy9FVlVuRHpSWWI5MUd2OERrbUdoTGVyMEIwVXV2dW93NDUyc3pFc2MwaWt5SVVBP3J0aW1lPU0wU0RLVkFWMlVn\n",
            "Reusing existing connection to dauam-my.sharepoint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 333331111 (318M) [application/x-zip-compressed]\n",
            "Saving to: ‘EVUnDzRYb91Gv8DkmGhLer0B0Uuvuow452szEsc0ikyIUA?download=1’\n",
            "\n",
            "EVUnDzRYb91Gv8DkmGh 100%[===================>] 317.89M  69.0MB/s    in 4.7s    \n",
            "\n",
            "2021-05-12 14:13:53 (67.2 MB/s) - ‘EVUnDzRYb91Gv8DkmGhLer0B0Uuvuow452szEsc0ikyIUA?download=1’ saved [333331111/333331111]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XQaCAvj71BX"
      },
      "source": [
        "## 1.2. Software para evaluación del sistema\n",
        "\n",
        "De cara a evaluar un sistema de diarización de locutores, podemos utilizar el siguiente toolbox (https://github.com/nryant/dscore):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sdgQjDB8coG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c55c091-483a-4955-ed95-965f650803c5"
      },
      "source": [
        "!git clone https://github.com/nryant/dscore.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dscore'...\n",
            "remote: Enumerating objects: 118, done.\u001b[K\n",
            "remote: Total 118 (delta 0), reused 0 (delta 0), pack-reused 118\u001b[K\n",
            "Receiving objects: 100% (118/118), 85.07 KiB | 6.08 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaaxGJY-8nC3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4fc007a-e32a-43ac-855d-90a126019d92"
      },
      "source": [
        "%cd dscore\n",
        "!cat requirements.txt\n",
        "!pip install -r requirements.txt\n",
        "%cd .."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/dscore\n",
            "intervaltree>=3.0.0\n",
            "numpy>=1.16.2\n",
            "scipy>=0.17.0\n",
            "tabulate>=0.5.0\n",
            "Collecting intervaltree>=3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/50/fb/396d568039d21344639db96d940d40eb62befe704ef849b27949ded5c3bb/intervaltree-3.1.0.tar.gz\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: tabulate>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.8.9)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3.0.0->-r requirements.txt (line 1)) (2.3.0)\n",
            "Building wheels for collected packages: intervaltree\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26102 sha256=b9b28c3e31a569ef6a826626b85cb41bb8dbc6c11464b7f53cae69a221211a02\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/f2/66/e9c30d3e9499e65ea2fa0d07c002e64de63bd0adaa49c445bf\n",
            "Successfully built intervaltree\n",
            "Installing collected packages: intervaltree\n",
            "  Found existing installation: intervaltree 2.1.0\n",
            "    Uninstalling intervaltree-2.1.0:\n",
            "      Successfully uninstalled intervaltree-2.1.0\n",
            "Successfully installed intervaltree-3.1.0\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12wBzbV_9LQU"
      },
      "source": [
        "Para utilizar la herramienta de scoring, utilizaríamos el siguiente comando:\n",
        "\n",
        "```\n",
        "!python score.py -r ref.rttm -s sys.rttm\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYB8CEgZ9Weq"
      },
      "source": [
        "## 1.3. Funciones auxiliares\n",
        "\n",
        "A continuación, se definen una serie de funciones que serán útiles de cara a implementar el sistema de diarización.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqYA2D6f-UoA"
      },
      "source": [
        "* _rttm2mat_: Esta función transforma un fichero RTTM en una matriz de #frames x #speakers, con etiquetas 1 / 0 dependiendo de si dicho locutor está presente en el instante temporal (frame) dado.\n",
        "Los frames correspondientes a silencio, tendrán todo 0, y se puede dar solapamiento de locutores (overlap) en cuyo caso los locutores correspondientes estarán marcados con un 1. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6RPimMTbDtl"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def rttm2mat(rttm_path, framerate=25, frameshift=10):\n",
        "    data  = np.loadtxt(rttm_path, usecols=[3,4]) \n",
        "    spks  = np.loadtxt(rttm_path, usecols=[7],dtype='str') \n",
        "    spk_ids = np.unique(spks) \n",
        "    Ns = len(spk_ids)\n",
        "\n",
        "    # There might be silence at the end of the file not covered by the rttm\n",
        "    len_file = data[-1][0]+data[-1][1] \n",
        "    \n",
        "    labels = np.zeros([int(len_file*1000),Ns]) \n",
        "    ranges = (np.array([data[:,0],data[:,0]+data[:,1]]).T*1000).astype(int) \n",
        "\n",
        "    for s in range(Ns): \n",
        "        for init_end in ranges[spks==spk_ids[s],:]: \n",
        "            labels[init_end[0]:init_end[1],s]=1  \n",
        "\n",
        "    fr_labels = labels[framerate//2::frameshift,:] \n",
        "    return fr_labels"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBtkI7CFBIk0"
      },
      "source": [
        "* _mat2rttm_: Esta función transforma a formato RTTM una matriz de predicciones como la indicada en la función anterior. El argumento _id_file_ es un campo del RTTM que se utiliza para identificar el fichero del que se está haciendo la diarización."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aykugS5GYCPE"
      },
      "source": [
        "def mat2rttm(predictions, id_file, out_rttm, frameshift=0.01, threshold=0.5):\n",
        "\n",
        "    hard_labels = np.zeros(predictions.shape)\n",
        "    hard_labels[predictions>=threshold] = 1\n",
        "    non_empty_spks = np.where(hard_labels.sum(axis=0)!=0)[0]\n",
        "    hard_labels = hard_labels[:,non_empty_spks]\n",
        "    \n",
        "    hard_labels = np.vstack([np.zeros((1,hard_labels.shape[1])), hard_labels])\n",
        "\n",
        "    d = np.diff(hard_labels, axis=0)\n",
        "    f = open(out_rttm, 'w')\n",
        "    n_spks = hard_labels.shape[1]\n",
        "    for spk in range(n_spks):\n",
        "        ini_indices = np.where(d[:,spk]==1)[0]\n",
        "        end_indices = np.where(d[:,spk]==-1)[0]\n",
        "        if (len(ini_indices) == len(end_indices) + 1):\n",
        "            end_indices = np.hstack([end_indices, predictions.shape[0]])\n",
        "        assert(len(ini_indices)==len(end_indices))\n",
        "        n_segments = len(ini_indices)\n",
        "        for index in range(n_segments):\n",
        "            f.write(('SPEAKER ' + id_file + ' 1 '\n",
        "                    + str(frameshift+ini_indices[index]*frameshift) + ' '\n",
        "                    + str((1+end_indices[index]-ini_indices[index])*frameshift) \n",
        "                    + ' <NA> <NA> ' + 'spk' + str(spk) + ' <NA> <NA>\\n'))\n",
        "    f.close()"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aDBvunLJRz3"
      },
      "source": [
        "* _rttm2labs.sh_: Este script transforma un fichero RTTM en un fichero de etiquetas con formato legible en Audacity. \n",
        "Por ejemplo: \"./rttm2labs.sh file1.rttm labs_file1\" genera el fichero labs_file1.txt. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKDxsSL4J7dc"
      },
      "source": [
        "#2. Implementando el sistema\n",
        "\n",
        "##2.1. Función de coste: BCE con permutational invariant training (PIT)\n",
        "\n",
        "Para comenzar a implementar el sistema de diarización \"end-to-end\", vamos a empezar por la función de coste. \n",
        "\n",
        "Tal y como se define en el artículo de referencia (sin tener en cuenta la parte de _deep_clustering_), la función de coste está definida como: \n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1PPgUHSdaf861BiBTY1LOwl8a9UV9OB_4\" width=\"300\">\n",
        "\n",
        "**PREGUNTA:**\n",
        "- Con la ayuda del artículo de referencia, implemente la función _PITLoss_ a continuación, e incluya el código en la memoria de la práctica."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ2FieP7HtiN"
      },
      "source": [
        "import torch\n",
        "from itertools import permutations\n",
        "from torch.nn.functional import binary_cross_entropy\n",
        "\n",
        "def PITLoss(pred, target):\n",
        "    \"\"\"Calculate PIT loss.\n",
        "\n",
        "    Input shape is (N, T, C), where:\n",
        "        - N: batch size\n",
        "        - T: sequence length\n",
        "        - C: number of speakers\n",
        "\n",
        "    Output is the average PIT loss for the whole batch. Note that\n",
        "    PytTorch's built-in `binary_cross_entropy` already computes the \n",
        "    average accross all axes, so there is no need to normalize.\n",
        "    \"\"\"\n",
        "    min_loss = np.inf\n",
        "    for target_perm in permutations(target.swapaxes(0, 2)):  # Permute in speakers axis\n",
        "        target_perm = torch.stack(target_perm)  # Reconstruct matrix from permuted vectors\n",
        "        target_perm = target_perm.swapaxes(0, 2)  # Recover original shape\n",
        "        loss = binary_cross_entropy(pred, target_perm, reduction='mean')\n",
        "        if loss < min_loss:\n",
        "            min_loss = loss\n",
        "    return min_loss"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LTmL3uxre0M"
      },
      "source": [
        "Probamos manualmente que funciona bien en un ejemplo muy sencillo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3c4iMi1Nlsw",
        "outputId": "a4bfab19-9821-4ca5-e72c-f7e84f48c0db"
      },
      "source": [
        "# Ground truth labels\n",
        "target = np.array([\n",
        "    # First batch element (seq1)\n",
        "    [[0, 0, 1, 1, 1, 0, 0, 0], \n",
        "    [0, 0, 0, 0, 0, 0, 1, 1]],\n",
        "    # Second batch element (seq2)\n",
        "    [[1, 0, 1, 1, 1, 0, 0, 0], \n",
        "    [1, 0, 0, 0, 0, 0, 1, 1]],\n",
        "], dtype=np.float64)\n",
        "\n",
        "# Predicted labels (should actually be probabilities)\n",
        "pred = np.array([\n",
        "    # First batch element (seq1)\n",
        "    [[0.5, 0, 1, 1, 1, 0, 0, 0], # <-- error in first component\n",
        "    [0, 0, 0, 0, 0, 0, 1, 1]],\n",
        "    # Second batch element (seq2)\n",
        "    [[1, 0, 1, 1, 1, 0, 0, 0], \n",
        "    [1, 0, 0, 0, 0, 0, 1, 1]],\n",
        "], dtype=np.float64)\n",
        "\n",
        "# Swap the last two dimensions and convert to tensors\n",
        "target = torch.tensor(np.transpose(target, (0, 2, 1)))\n",
        "pred = torch.tensor(np.transpose(pred, (0, 2, 1)))\n",
        "\n",
        "bce = PITLoss(pred, target)\n",
        "print(f\"Average batch loss: {bce:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average batch loss: 0.0217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmhQdJAXPTp_"
      },
      "source": [
        "##2.2. Definición del modelo\n",
        "\n",
        "Ahora, vamos a definir el modelo de acuerdo al artículo: \n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1yQ_Un-LirKOTwWG1oFxVALSztv4ZmPFx\" width=\"400\">\n",
        "\n",
        "**PREGUNTA:**\n",
        "- Defina la clase BLSTM_5layers con la configuración del modelo del artículo: El modelo tiene 5 capas BLSTM de 256 unidades cada una, y recibe características de dimensión 23. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck6ITgaZ5W9b"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BLSTM_5layers(nn.Module):\n",
        "    def __init__(self, feat_dim=23, nclasses=2):\n",
        "        super(BLSTM_5layers, self).__init__()\n",
        "        self.blstm = nn.LSTM(feat_dim, 256, batch_first=True, \n",
        "                             bidirectional=True, num_layers=5)\n",
        "        self.linear = nn.Linear(2*256, nclasses)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Input is (batch_size, seq_length, feat_dim)\"\"\"\n",
        "        out = self.blstm(x)[0]\n",
        "        out = self.linear(out)\n",
        "        out = torch.sigmoid(out)\n",
        "        return out"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIBq-2CoQuEM"
      },
      "source": [
        "##2.3. Entrenamiento del sistema\n",
        "\n",
        "Ahora vamos a completar la implementación del sistema, para realizar su entrenamiento.\n",
        "\n",
        "Reutilizando código de prácticas anteriores, recuerda los pasos principales, y ten en cuenta las peculiaridades para esta práctica: \n",
        "- Cargar la lista de identificadores de entrenamiento. \n",
        "- Declarar el modelo y cargarlo a la GPU. \n",
        "- Declarar la función de coste (implementada previamente, PITLoss) y el optimizador. \n",
        "- En lugar de generar minibatches con una longitud fija de secuencias, puedes utilizar un tamaño de batch de _1_ y utilizar fichero a fichero.\n",
        "- Para leer un audio puedes utilizar la función _read_recording_ de prácticas anteriores. \n",
        "- El tipo de parámetros o características (features) no tiene por qué ser exactamente el del artículo de referencia. Puedes utilizar por ejemplo _melspectrogram_ de la librería _librosa_.\n",
        "- Puesto que las secuencias de características y las etiquetas deben tener la misma longitud, y el RTTM puede contener silencio al final, puedes realizar un _padding_ de las etiquetas a 0 hasta completar la longitud del audio (o recortar la secuencia de _features_). \n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7POm3_R21LLo"
      },
      "source": [
        "**PREGUNTA:**\n",
        "- Completa el código siguiente e inclúyelo en la memoria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJWrUylYytdQ"
      },
      "source": [
        "import scipy.io.wavfile\n",
        "\n",
        "def read_recording(wav_file_name): \n",
        "  fs, signal = scipy.io.wavfile.read(wav_file_name)\n",
        "  signal = signal/max(abs(signal)) # normalizes amplitude\n",
        "  \n",
        "  return fs, signal"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjV5lm5AJXjH"
      },
      "source": [
        "# LISTA DE ENTRENAMIENTO\n",
        "TRAIN_PATH_FEATS = 'data/train_2spk/wav/'\n",
        "TRAIN_PATH_LABS = 'data/train_2spk/rttm/'\n",
        "with open('train_DIAR_2spk.lst', 'r') as f:\n",
        "    train_list = f.read().splitlines()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUBhgYruUKfI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7384cccc-8741-4b5b-ff7b-200208ad86c0"
      },
      "source": [
        "from torch import optim\n",
        "import librosa\n",
        "\n",
        "train = True\n",
        "trim_features = True\n",
        "max_iters = 5\n",
        "if train:\n",
        "    # MODELO\n",
        "    device = torch.device(\"cuda\")\n",
        "    model = BLSTM_5layers()\n",
        "    model = model.to(device)\n",
        "\n",
        "    # CRITERIOS DE OPTIMIZACIÓN\n",
        "    criterion = PITLoss\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    losses = []\n",
        "    for epoch in range(1, max_iters + 1):\n",
        "        model.train()\n",
        "        cache_loss = 0.0\n",
        "\n",
        "        # Batch size is 1\n",
        "        for file_id in train_list:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Create training sample\n",
        "            fs, signal = read_recording(TRAIN_PATH_FEATS + file_id + \".wav\")\n",
        "            # 25ms frame length and 10ms frame shift (at fs=16000)\n",
        "            feats = librosa.feature.melspectrogram(\n",
        "                signal, fs, n_mels=23, win_length=400, hop_length=160)\n",
        "            feats = feats.T  # n_frames x n_features\n",
        "\n",
        "            labs = rttm2mat(TRAIN_PATH_LABS + file_id + \".rttm\")  # n_frames x n_speakers\n",
        "            if trim_features:\n",
        "                feats = feats[:len(labs), :]\n",
        "            else:\n",
        "                labs = np.pad(labs, [(0, len(feats) - len(labs)), (0, 0)])\n",
        "\n",
        "            # Make sure that all frames have defined label\n",
        "            assert len(labs) == len(feats) \n",
        "\n",
        "            # Place data into Pytorch tensors\n",
        "            feats = torch.tensor(feats[np.newaxis, :].astype(\"float32\")).to(device)\n",
        "            labs = torch.tensor(labs[np.newaxis, :].astype(\"float32\")).to(device)\n",
        "            \n",
        "            # Forward the data through the network\n",
        "            outputs = model(feats)\n",
        "\n",
        "            # Compute cost\n",
        "            loss = criterion(outputs, labs)\n",
        "\n",
        "            # Backward step\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            cache_loss += loss.item()\n",
        "\n",
        "        epoch_loss = cache_loss/len(train_list)\n",
        "        losses.append(epoch_loss)\n",
        "        print(f'[{epoch:02d}] loss: {epoch_loss:03f}')\n",
        "\n",
        "        # Save model after each epoch\n",
        "        if trim_features:\n",
        "            torch.save(model.state_dict(), DIR + 'model_trimmed_features.pt')\n",
        "        else:\n",
        "            torch.save(model.state_dict(), DIR + 'model_pad.pt')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[01] loss: 0.611003\n",
            "[02] loss: 0.580144\n",
            "[03] loss: 0.578037\n",
            "[04] loss: 0.579590\n",
            "[05] loss: 0.575558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI2FhZPq3hGV"
      },
      "source": [
        "##2.4. Evaluación: DER (Diarization Error Rate)\n",
        "\n",
        "Finalmente, realiza la evaluación de dos ficheros al azar (dentro del conjunto de entrenamiento) y obtén el DER para cada uno de ellos utilizando el toolbox _dscore_ presentado al inicio de la práctica.\n",
        "\n",
        "**PREGUNTA:**\n",
        "- Incluye en la memoria el código utilizado, los identificadores de los ficheros elegidos y sus correspondientes errores (DER).\n",
        "- ¿Cómo se interpreta el DER? \n",
        "- ¿Puede tener un valor mayor de 100%?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kIoXeJF6pSj"
      },
      "source": [
        "# Load pre-trained model\n",
        "device = torch.device(\"cuda\")\n",
        "model = BLSTM_5layers()\n",
        "model.load_state_dict(torch.load(DIR + 'model.pt'))\n",
        "model = model.to(device)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXbEM0DR-RVn"
      },
      "source": [
        "import librosa\n",
        "\n",
        "def predict(file_id):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        fs, signal = read_recording(TRAIN_PATH_FEATS + file_id + \".wav\")\n",
        "        feats = librosa.feature.melspectrogram(\n",
        "            signal, fs, n_mels=23, win_length=400, hop_length=160)\n",
        "        feats = torch.tensor(feats.T[np.newaxis, :].astype(\"float32\")).to(device)\n",
        "        outputs = model(feats).cpu()[0]\n",
        "    return outputs"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPTacJ2fa50h"
      },
      "source": [
        "for file_id in train_list:\n",
        "    preds = predict(file_id)\n",
        "    mat2rttm(preds, file_id, file_id + '_pred.rttm')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaxJNpC3brJ6",
        "outputId": "ade2e3bf-9a6d-4f65-dd24-e8959e741aa2"
      },
      "source": [
        "!python dscore/score.py -r data/train_2spk/rttm/*.rttm \\\n",
        "    -s *_pred.rttm"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading speaker turns from reference RTTMs...\n",
            "Loading speaker turns from system RTTMs...\n",
            "WARNING: No universal evaluation map specified. Approximating from reference and speaker turn extents...\n",
            "Trimming reference speaker turns to UEM scoring regions...\n",
            "Trimming system speaker turns to UEM scoring regions...\n",
            "Checking for overlapping reference speaker turns...\n",
            "Checking for overlapping system speaker turns...\n",
            "Scoring...\n",
            "File               DER    JER    B3-Precision    B3-Recall    B3-F1    GKT(ref, sys)    GKT(sys, ref)    H(ref|sys)    H(sys|ref)    MI    NMI\n",
            "---------------  -----  -----  --------------  -----------  -------  ---------------  ---------------  ------------  ------------  ----  -----\n",
            "akthc            25.39  61.66            0.62         1.00     0.76             1.00             0.00          1.00          0.00  0.00   0.00\n",
            "bkwns            44.34  65.92            0.55         1.00     0.71             1.00             0.00          1.07          0.00  0.00   0.00\n",
            "blwmj            41.27  69.87            0.49         1.00     0.66             1.00             0.00          1.17          0.00  0.00   0.00\n",
            "cobal            11.68  55.82            0.79         1.00     0.88             0.00             0.00          0.54          0.00  0.00   0.00\n",
            "crixb            52.42  72.13            0.37         1.00     0.54             1.00             0.00          1.63          0.00  0.00   0.00\n",
            "djngn            34.01  66.18            0.53         1.00     0.70             1.00             0.00          1.11          0.00  0.00   0.00\n",
            "dscgs            49.24  72.73            0.43         1.00     0.61             1.00             0.00          1.38          0.00  0.00   0.00\n",
            "eqttu            36.96  68.43            0.53         1.00     0.70             1.00             0.00          0.97          0.00  0.00   0.00\n",
            "evtyi            47.74  66.81            0.53         1.00     0.69             1.00             0.00          1.10          0.00  0.00   0.00\n",
            "fxgvy            46.51  72.17            0.47         1.00     0.64             1.00             0.00          1.25          0.00  0.00   0.00\n",
            "gpjne            24.83  61.53            0.61         1.00     0.76             1.00             0.00          1.00          0.00  0.00   0.00\n",
            "hiyis            48.41  73.91            0.49         1.00     0.66             0.00             0.00          1.08          0.00  0.00   0.00\n",
            "hkzpa            40.27  68.53            0.48         1.00     0.64             1.00             0.00          1.29          0.00  0.00   0.00\n",
            "hycgx            29.97  63.58            0.55         1.00     0.71             1.00             0.00          1.16          0.00  0.00   0.00\n",
            "ikgcq            26.04  60.34            0.65         1.00     0.79             1.00             0.00          0.93          0.00  0.00   0.00\n",
            "imtug            22.28  59.88            0.65         1.00     0.79             1.00             0.00          0.99          0.00  0.00   0.00\n",
            "kctgl            48.42  72.91            0.46         1.00     0.63             1.00             0.00          1.28          0.00  0.00   0.00\n",
            "kklpv            19.89  59.44            0.67         1.00     0.81             1.00             0.00          0.84          0.00  0.00   0.00\n",
            "mekog            29.86  64.10            0.56         1.00     0.72             1.00             0.00          1.06          0.00  0.00   0.00\n",
            "mjgil            11.29  55.45            0.80         1.00     0.89             0.00             0.00          0.59          0.00  0.00   0.00\n",
            "mpvoh            41.11  67.94            0.44         1.00     0.61             1.00             0.00          1.40          0.00  0.00   0.00\n",
            "mwfmq             8.35  53.89            0.86         1.00     0.92             1.00             0.00          0.43          0.00  0.00   0.00\n",
            "ngyrk            46.68  69.54            0.40         1.00     0.57             1.00             0.00          1.57          0.00  0.00   0.00\n",
            "ntchr            34.12  66.51            0.54         1.00     0.70             1.00             0.00          1.07          0.00  0.00   0.00\n",
            "nxgad            45.73  67.29            0.36         1.00     0.53             0.00             0.00          1.55          0.00  0.00   0.00\n",
            "oenox            24.33  61.52            0.63         1.00     0.77             1.00             0.00          0.96          0.00  0.00   0.00\n",
            "oxxwk            41.83  67.62            0.48         1.00     0.65             1.00             0.00          1.29          0.00  0.00   0.00\n",
            "plbbw            16.75  57.26            0.75         1.00     0.86             1.00             0.00          0.66          0.00  0.00   0.00\n",
            "ppgjx            41.40  67.24            0.48         1.00     0.65             1.00             0.00          1.34          0.00  0.00   0.00\n",
            "praxo            43.31  70.41            0.47         1.00     0.64             0.00             0.00          1.26          0.00  0.00   0.00\n",
            "qhesr             9.99  54.83            0.82         1.00     0.90             1.00             0.00          0.55          0.00  0.00   0.00\n",
            "qpylu            71.34  76.02            0.37         1.00     0.54             1.00             0.00          1.52          0.00  0.00   0.00\n",
            "qsfzo            34.72  66.82            0.53         1.00     0.69             1.00             0.00          1.07          0.00  0.00   0.00\n",
            "qvtia            85.97  76.43            0.39         1.00     0.56             1.00             0.00          1.44          0.00  0.00   0.00\n",
            "qzwxa            21.67  60.36            0.66         1.00     0.79             1.00             0.00          0.89          0.00  0.00   0.00\n",
            "spzmn            11.16  55.37            0.80         1.00     0.89             0.00             0.00          0.57          0.00  0.00   0.01\n",
            "tcwsn            38.26  67.85            0.49         1.00     0.66             0.00             0.00          1.23          0.00  0.00   0.00\n",
            "whmpa            26.09  60.03            0.63         1.00     0.78             0.00             0.00          1.00          0.00  0.00   0.00\n",
            "willh            56.41  75.78            0.43         1.00     0.60             1.00             0.00          1.33          0.00  0.00   0.00\n",
            "wmori            65.68  76.77            0.37         1.00     0.54             1.00             0.00          1.49          0.00  0.00   0.00\n",
            "yuzyu            40.62  68.85            0.47         1.00     0.64             1.00             0.00          1.22          0.00  0.00   0.00\n",
            "ywcwr            36.26  66.92            0.52         1.00     0.68             1.00             0.00          1.17          0.00  0.00   0.00\n",
            "zajzs            17.14  56.99            0.70         1.00     0.82             0.00             0.00          0.83          0.00  0.00   0.01\n",
            "zrlyl            27.73  61.44            0.57         1.00     0.72             1.00             0.00          1.21          0.00  0.00   0.00\n",
            "*** OVERALL ***  35.19  65.57            0.55         1.00     0.71             1.00             0.54          1.12          0.00  5.01   0.90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m42UQmLl9MuT"
      },
      "source": [
        "Elegimos los ficheros con índices 5 y 10, correspondiente a los identificadores `djngn` y `gpjne`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mWLQHdy8j4I"
      },
      "source": [
        "# Create rttm for predictions\n",
        "valid_idx = [5, 10]\n",
        "for idx in valid_idx:\n",
        "    file_id = train_list[idx]\n",
        "    preds = predict(file_id)\n",
        "    mat2rttm(preds, file_id, file_id + '_pred.rttm')"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDvfQR9b8muI",
        "outputId": "708441a3-1968-474f-c73b-2eaed20e3e68"
      },
      "source": [
        "!python dscore/score.py -r data/train_2spk/rttm/djngn.rttm \\\n",
        "    data/train_2spk/rttm/gpjne.rttm \\\n",
        "    -s djngn_pred.rttm gpjne_pred.rttm"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading speaker turns from reference RTTMs...\n",
            "Loading speaker turns from system RTTMs...\n",
            "WARNING: No universal evaluation map specified. Approximating from reference and speaker turn extents...\n",
            "Trimming reference speaker turns to UEM scoring regions...\n",
            "Trimming system speaker turns to UEM scoring regions...\n",
            "Checking for overlapping reference speaker turns...\n",
            "Checking for overlapping system speaker turns...\n",
            "Scoring...\n",
            "File               DER    JER    B3-Precision    B3-Recall    B3-F1    GKT(ref, sys)    GKT(sys, ref)    H(ref|sys)    H(sys|ref)    MI    NMI\n",
            "---------------  -----  -----  --------------  -----------  -------  ---------------  ---------------  ------------  ------------  ----  -----\n",
            "djngn            33.97  66.17            0.54         1.00     0.70             1.00             0.00          1.11          0.00  0.00   0.00\n",
            "gpjne            24.83  61.53            0.61         1.00     0.76             1.00             0.00          1.00          0.00  0.00   0.00\n",
            "*** OVERALL ***  29.15  63.85            0.57         1.00     0.73             1.00             0.40          1.05          0.00  1.00   0.70\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}